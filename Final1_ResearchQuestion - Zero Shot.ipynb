{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import random\n",
    "import glob as glob\n",
    "\n",
    "import base64\n",
    "from typing import List, Dict, Any\n",
    "from openai import OpenAI\n",
    "import anthropic, openai, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HelperFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY = 'sk-proj-gcAGyvxZkoN5Y9zCm38sT3BlbkFJ6mUU5iNsWW82SFmx5w2D'\n",
    "client_openai = OpenAI(\n",
    "  organization='org-5fSHohPvEjmwCaPjyyo1ydl6',\n",
    "  api_key = OPENAI_KEY\n",
    ")\n",
    "\n",
    "client_anthropic = anthropic.Anthropic(api_key='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Shot Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1: How well do LLMs classify images belonging to Natural Classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for CIFAR10 sample\n",
    "dataset = 'CIFAR10'\n",
    "dataset_classes = list(class_ground_truth_mapping[dataset].values())\n",
    "\n",
    "samples_to_use = get_samples_from_each_folder(f'./Datasets/{dataset}/test', 10)\n",
    "ground_truths_for_samples = get_ground_truth_from_path(samples_to_use, dataset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1000\n",
      "Mean Bootstrap Accuracy: 0.1002\n",
      "Standard Deviation of Bootstrap Accuracies: 0.029921\n"
     ]
    }
   ],
   "source": [
    "# Compute result for Anthropic\n",
    "zero_shot_cifar10_anthropic_preds_file = 'zero_shot_cifar10_anthropic_preds.txt'\n",
    "if os.path.exists(zero_shot_cifar10_anthropic_preds_file):\n",
    "    # print(f\"File {zero_shot_cifar10_anthropic_preds_file} exists. Load Results...\")\n",
    "    anthropic_preds = load_list_from_file(zero_shot_cifar10_anthropic_preds_file)\n",
    "\n",
    "    matching_count = count_matching_samples_positionwise(anthropic_preds, ground_truths_for_samples)\n",
    "    accuracy_anthropic = matching_count / len(ground_truths_for_samples)\n",
    "    # Add your code here for when the file exists\n",
    "else:\n",
    "    print(f\"File {zero_shot_cifar10_anthropic_preds_file} does not exist. Creating ...\")\n",
    "    # Add your code here for when the file doesn't exist\n",
    "    accuracy_anthropic, anthropic_preds = get_class_samples(\n",
    "        client_anthropic, \n",
    "        samples_to_use, \n",
    "        dataset_classes, \n",
    "        dataset,\n",
    "        ground_truths_for_samples, \n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"Claude\"  # or whatever model identifier you use for Anthropic\n",
    "    )\n",
    "\n",
    "    save_list_to_file(anthropic_preds, zero_shot_cifar10_anthropic_preds_file)\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(anthropic_preds, ground_truths_for_samples)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9800\n",
      "Mean Bootstrap Accuracy: 0.9794\n",
      "Standard Deviation of Bootstrap Accuracies: 0.014499\n"
     ]
    }
   ],
   "source": [
    "# Compute result for OpenAI GPT-4\n",
    "zero_shot_cifar10_openai_gpt4o_preds_file = 'zero_shot_cifar10_openai_gpt4o_preds.txt'\n",
    "\n",
    "if os.path.exists(zero_shot_cifar10_openai_gpt4o_preds_file):\n",
    "    # print(f\"File {zero_shot_cifar10_openai_gpt4o_preds_file} exists. Loading Results...\")\n",
    "    openai_gpt4o_preds = load_list_from_file(zero_shot_cifar10_openai_gpt4o_preds_file)\n",
    "    matching_count = count_matching_samples_positionwise(openai_gpt4o_preds, ground_truths_for_samples)\n",
    "    accuracy_openai_gpt4o = matching_count / len(ground_truths_for_samples)\n",
    "else:\n",
    "    print(f\"File {zero_shot_cifar10_openai_gpt4o_preds_file} does not exist. Creating ...\")\n",
    "    accuracy_openai_gpt4o, openai_gpt4o_preds = get_class_samples(\n",
    "        client_openai,\n",
    "        samples_to_use,\n",
    "        dataset_classes,\n",
    "        dataset,\n",
    "        ground_truths_for_samples,\n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"gpt-4o\"  # or \"GPT4o-mini\" for the smaller model\n",
    "    )\n",
    "    save_list_to_file(openai_gpt4o_preds, zero_shot_cifar10_openai_gpt4o_preds_file)\n",
    "\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(openai_gpt4o_preds, ground_truths_for_samples)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9500\n",
      "Mean Bootstrap Accuracy: 0.9503\n",
      "Standard Deviation of Bootstrap Accuracies: 0.022227\n"
     ]
    }
   ],
   "source": [
    "# Compute result for OpenAI GPT-4-mini\n",
    "zero_shot_cifar10_openai_gpt4o_mini_preds_file = 'zero_shot_cifar10_openai_gpt4o_mini_preds.txt'\n",
    "\n",
    "if os.path.exists(zero_shot_cifar10_openai_gpt4o_mini_preds_file):\n",
    "    # print(f\"File {zero_shot_cifar10_openai_gpt4o_mini_preds_file} exists. Loading Results...\")\n",
    "    openai_gpt4o_mini_preds = load_list_from_file(zero_shot_cifar10_openai_gpt4o_mini_preds_file)\n",
    "    matching_count = count_matching_samples_positionwise(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
    "    accuracy_openai_gpt4o_mini = matching_count / len(ground_truths_for_samples)\n",
    "else:\n",
    "    print(f\"File {zero_shot_cifar10_openai_gpt4o_mini_preds_file} does not exist. Creating ...\")\n",
    "    accuracy_openai_gpt4o_mini, openai_gpt4o_mini_preds = get_class_samples(\n",
    "        client_openai,\n",
    "        samples_to_use,\n",
    "        dataset_classes,\n",
    "        dataset,\n",
    "        ground_truths_for_samples,\n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"gpt-4o-mini\"  # The smaller GPT-4 model\n",
    "    )\n",
    "    save_list_to_file(openai_gpt4o_mini_preds, zero_shot_cifar10_openai_gpt4o_mini_preds_file)\n",
    "\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for CIFAR10 sample\n",
    "dataset = 'STL10'\n",
    "dataset_classes = list(class_ground_truth_mapping[dataset].values())\n",
    "\n",
    "samples_to_use = get_samples_from_each_folder(f'./Datasets/{dataset}/test', 10)\n",
    "ground_truths_for_samples = get_ground_truth_from_path(samples_to_use, dataset_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2200\n",
      "Mean Bootstrap Accuracy: 0.2215\n",
      "Standard Deviation of Bootstrap Accuracies: 0.042158\n"
     ]
    }
   ],
   "source": [
    "# Compute result for Anthropic\n",
    "zero_shot_stl10_anthropic_preds_file = 'zero_shot_stl10_anthropic_preds.txt'\n",
    "if os.path.exists(zero_shot_stl10_anthropic_preds_file):\n",
    "    # print(f\"File {zero_shot_stl10_anthropic_preds_file} exists. Load Results...\")\n",
    "    anthropic_preds = load_list_from_file(zero_shot_stl10_anthropic_preds_file)\n",
    "\n",
    "    matching_count = count_matching_samples_positionwise(anthropic_preds, ground_truths_for_samples)\n",
    "    accuracy_anthropic = matching_count / len(ground_truths_for_samples)\n",
    "    # Add your code here for when the file exists\n",
    "else:\n",
    "    print(f\"File {zero_shot_stl10_anthropic_preds_file} does not exist. Creating ...\")\n",
    "    # Add your code here for when the file doesn't exist\n",
    "    accuracy_anthropic, anthropic_preds = get_class_samples(\n",
    "        client_anthropic, \n",
    "        samples_to_use, \n",
    "        dataset_classes, \n",
    "        dataset,\n",
    "        ground_truths_for_samples, \n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"Claude\"  # or whatever model identifier you use for Anthropic\n",
    "    )\n",
    "\n",
    "    save_list_to_file(anthropic_preds, zero_shot_stl10_anthropic_preds_file)\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(anthropic_preds, ground_truths_for_samples)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9700\n",
      "Mean Bootstrap Accuracy: 0.9708\n",
      "Standard Deviation of Bootstrap Accuracies: 0.016859\n"
     ]
    }
   ],
   "source": [
    "# Compute result for OpenAI GPT-4o\n",
    "zero_shot_stl10_openai_gpt4o_preds_file = 'zero_shot_stl10_openai_gpt4o_preds.txt'\n",
    "\n",
    "if os.path.exists(zero_shot_stl10_openai_gpt4o_preds_file):\n",
    "    # print(f\"File {zero_shot_stl10_openai_gpt4o_preds_file} exists. Loading Results...\")\n",
    "    openai_gpt4o_preds = load_list_from_file(zero_shot_stl10_openai_gpt4o_preds_file)\n",
    "    matching_count = count_matching_samples_positionwise(openai_gpt4o_preds, ground_truths_for_samples)\n",
    "    accuracy_openai_gpt4o = matching_count / len(ground_truths_for_samples)\n",
    "else:\n",
    "    print(f\"File {zero_shot_stl10_openai_gpt4o_preds_file} does not exist. Creating ...\")\n",
    "    accuracy_openai_gpt4o, openai_gpt4o_preds = get_class_samples(\n",
    "        client_openai,\n",
    "        samples_to_use,\n",
    "        dataset_classes,\n",
    "        dataset,\n",
    "        ground_truths_for_samples,\n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"gpt-4o\"  # or \"GPT4o-mini\" for the smaller model\n",
    "    )\n",
    "    save_list_to_file(openai_gpt4o_preds, zero_shot_stl10_openai_gpt4o_preds_file)\n",
    "\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(openai_gpt4o_preds, ground_truths_for_samples)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9800\n",
      "Mean Bootstrap Accuracy: 0.9803\n",
      "Standard Deviation of Bootstrap Accuracies: 0.013838\n"
     ]
    }
   ],
   "source": [
    "# Compute result for OpenAI GPT-4-mini\n",
    "zero_shot_stl10_openai_gpt4o_mini_preds_file = 'zero_shot_stl10_openai_gpt4o_mini_preds.txt'\n",
    "\n",
    "if os.path.exists(zero_shot_stl10_openai_gpt4o_mini_preds_file):\n",
    "    # print(f\"File {zero_shot_stl10_openai_gpt4o_mini_preds_file} exists. Loading Results...\")\n",
    "    openai_gpt4o_mini_preds = load_list_from_file(zero_shot_stl10_openai_gpt4o_mini_preds_file)\n",
    "    matching_count = count_matching_samples_positionwise(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
    "    accuracy_openai_gpt4o_mini = matching_count / len(ground_truths_for_samples)\n",
    "else:\n",
    "    print(f\"File {zero_shot_stl10_openai_gpt4o_mini_preds_file} does not exist. Creating ...\")\n",
    "    accuracy_openai_gpt4o_mini, openai_gpt4o_mini_preds = get_class_samples(\n",
    "        client_openai,\n",
    "        samples_to_use,\n",
    "        dataset_classes,\n",
    "        dataset,\n",
    "        ground_truths_for_samples,\n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"gpt-4o-mini\"  # The smaller GPT-4 model\n",
    "    )\n",
    "    save_list_to_file(openai_gpt4o_mini_preds, zero_shot_stl10_openai_gpt4o_mini_preds_file)\n",
    "\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PneumoniaMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for CIFAR10 sample\n",
    "dataset = 'PneumoniaMNIST'\n",
    "dataset_classes = list(class_ground_truth_mapping[dataset].values())\n",
    "\n",
    "samples_to_use = get_samples_from_each_folder(f'./Datasets/{dataset}/test', 50)\n",
    "ground_truths_for_samples = get_ground_truth_from_path(samples_to_use, dataset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4800\n",
      "Mean Bootstrap Accuracy: 0.4751\n",
      "Standard Deviation of Bootstrap Accuracies: 0.048865\n"
     ]
    }
   ],
   "source": [
    "# Compute result for Anthropic\n",
    "zero_shot_pneumoniamnist_anthropic_preds_file = 'zero_shot_pneumoniamnist_anthropic_preds.txt'\n",
    "if os.path.exists(zero_shot_pneumoniamnist_anthropic_preds_file):\n",
    "    # print(f\"File {zero_shot_pneumoniamnist_anthropic_preds_file} exists. Load Results...\")\n",
    "    anthropic_preds = load_list_from_file(zero_shot_pneumoniamnist_anthropic_preds_file)\n",
    "\n",
    "    matching_count = count_matching_samples_positionwise(anthropic_preds, ground_truths_for_samples)\n",
    "    accuracy_anthropic = matching_count / len(ground_truths_for_samples)\n",
    "    # Add your code here for when the file exists\n",
    "else:\n",
    "    print(f\"File {zero_shot_pneumoniamnist_anthropic_preds_file} does not exist. Creating ...\")\n",
    "    # Add your code here for when the file doesn't exist\n",
    "    accuracy_anthropic, anthropic_preds = get_class_samples(\n",
    "        client_anthropic, \n",
    "        samples_to_use, \n",
    "        dataset_classes, \n",
    "        dataset,\n",
    "        ground_truths_for_samples, \n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"Claude\"  # or whatever model identifier you use for Anthropic\n",
    "    )\n",
    "\n",
    "    save_list_to_file(anthropic_preds, zero_shot_pneumoniamnist_anthropic_preds_file)\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(anthropic_preds, ground_truths_for_samples)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8200\n",
      "Mean Bootstrap Accuracy: 0.8189\n",
      "Standard Deviation of Bootstrap Accuracies: 0.037294\n"
     ]
    }
   ],
   "source": [
    "# Compute result for OpenAI GPT-4o\n",
    "zero_shot_pneumoniamnist_openai_gpt4o_preds_file = 'zero_shot_pneumoniamnist_openai_gpt4o_preds.txt'\n",
    "\n",
    "if os.path.exists(zero_shot_pneumoniamnist_openai_gpt4o_preds_file):\n",
    "    # print(f\"File {zero_shot_pneumoniamnist_openai_gpt4o_preds_file} exists. Loading Results...\")\n",
    "    openai_gpt4o_preds = load_list_from_file(zero_shot_pneumoniamnist_openai_gpt4o_preds_file)\n",
    "    matching_count = count_matching_samples_positionwise(openai_gpt4o_preds, ground_truths_for_samples)\n",
    "    accuracy_openai_gpt4o = matching_count / len(ground_truths_for_samples)\n",
    "else:\n",
    "    print(f\"File {zero_shot_pneumoniamnist_openai_gpt4o_preds_file} does not exist. Creating ...\")\n",
    "    accuracy_openai_gpt4o, openai_gpt4o_preds = get_class_samples(\n",
    "        client_openai,\n",
    "        samples_to_use,\n",
    "        dataset_classes,\n",
    "        dataset,\n",
    "        ground_truths_for_samples,\n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"gpt-4o\"  # or \"GPT4o-mini\" for the smaller model\n",
    "    )\n",
    "    save_list_to_file(openai_gpt4o_preds, zero_shot_pneumoniamnist_openai_gpt4o_preds_file)\n",
    "\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(openai_gpt4o_preds, ground_truths_for_samples)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File zero_shot_pneumoniamnist_openai_gpt4o_mini_preds.txt does not exist. Creating ...\n",
      "Failed to extract valid JSON from the response.\n",
      "Model predictions: []\n",
      "Ground truths: ['pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal', 'normal', 'normal', 'pneumonia', 'normal', 'pneumonia', 'normal']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzero_shot_pneumoniamnist_openai_gpt4o_mini_preds_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist. Creating ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     accuracy_openai_gpt4o_mini, openai_gpt4o_mini_preds \u001b[38;5;241m=\u001b[39m \u001b[43mget_class_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_openai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43msamples_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mground_truths_for_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43munified_zero_shot_predict_class_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# The smaller GPT-4 model\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     save_list_to_file(openai_gpt4o_mini_preds, zero_shot_pneumoniamnist_openai_gpt4o_mini_preds_file)\n\u001b[1;32m     22\u001b[0m accuracy, mean_acc, var_acc, z_score, p_value \u001b[38;5;241m=\u001b[39m compute_statistical_significance(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
      "File \u001b[0;32m~/Documents/med_gpt/HelperFunctions.py:240\u001b[0m, in \u001b[0;36mget_class_samples\u001b[0;34m(client, list_of_images, classes_to_classify, dataset_name, ground_truths, func_to_call, model, image_media_type)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Compare the predictions with the ground truth\u001b[39;00m\n\u001b[1;32m    239\u001b[0m matching_count \u001b[38;5;241m=\u001b[39m count_matching_samples_positionwise(preds, ground_truths)\n\u001b[0;32m--> 240\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmatching_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mground_truths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, preds\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# Compute result for OpenAI GPT-4o-mini\n",
    "zero_shot_pneumoniamnist_openai_gpt4o_mini_preds_file = 'zero_shot_pneumoniamnist_openai_gpt4o_mini_preds.txt'\n",
    "\n",
    "if os.path.exists(zero_shot_pneumoniamnist_openai_gpt4o_mini_preds_file):\n",
    "    # print(f\"File {zero_shot_pneumoniamnist_openai_gpt4o_mini_preds_file} exists. Loading Results...\")\n",
    "    openai_gpt4o_mini_preds = load_list_from_file(zero_shot_pneumoniamnist_openai_gpt4o_mini_preds_file)\n",
    "    matching_count = count_matching_samples_positionwise(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
    "    accuracy_openai_gpt4o_mini = matching_count / len(ground_truths_for_samples)\n",
    "else:\n",
    "    print(f\"File {zero_shot_pneumoniamnist_openai_gpt4o_mini_preds_file} does not exist. Creating ...\")\n",
    "    accuracy_openai_gpt4o_mini, openai_gpt4o_mini_preds = get_class_samples(\n",
    "        client_openai,\n",
    "        samples_to_use,\n",
    "        dataset_classes,\n",
    "        dataset,\n",
    "        ground_truths_for_samples,\n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"gpt-4o-mini\"  # The smaller GPT-4 model\n",
    "    )\n",
    "    save_list_to_file(openai_gpt4o_mini_preds, zero_shot_pneumoniamnist_openai_gpt4o_mini_preds_file)\n",
    "\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DermaMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for CIFAR10 sample\n",
    "dataset = 'DermaMNIST'\n",
    "dataset_classes = list(class_ground_truth_mapping[dataset].values())\n",
    "\n",
    "samples_to_use = get_samples_from_each_folder(f'./Datasets/{dataset}/test', 15)[:10]\n",
    "ground_truths_for_samples = get_ground_truth_from_path(samples_to_use, dataset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute result for Anthropic\n",
    "zero_shot_dermamnist_anthropic_preds_file = 'zero_shot_dermamnist_anthropic_preds.txt'\n",
    "if os.path.exists(zero_shot_dermamnist_anthropic_preds_file):\n",
    "    # print(f\"File {zero_shot_dermamnist_anthropic_preds_file} exists. Load Results...\")\n",
    "    anthropic_preds = load_list_from_file(zero_shot_dermamnist_anthropic_preds_file)\n",
    "\n",
    "    matching_count = count_matching_samples_positionwise(anthropic_preds, ground_truths_for_samples)\n",
    "    accuracy_anthropic = matching_count / len(ground_truths_for_samples)\n",
    "    # Add your code here for when the file exists\n",
    "else:\n",
    "    print(f\"File {zero_shot_dermamnist_anthropic_preds_file} does not exist. Creating ...\")\n",
    "    # Add your code here for when the file doesn't exist\n",
    "    accuracy_anthropic, anthropic_preds = get_class_samples(\n",
    "        client_anthropic, \n",
    "        samples_to_use, \n",
    "        dataset_classes, \n",
    "        dataset,\n",
    "        ground_truths_for_samples, \n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"Claude\"  # or whatever model identifier you use for Anthropic\n",
    "    )\n",
    "\n",
    "    save_list_to_file(anthropic_preds, zero_shot_dermamnist_anthropic_preds_file)\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(anthropic_preds, ground_truths_for_samples)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dermatofibroma',\n",
       " 'vascular lesions',\n",
       " 'actinic keratoses and intraepithelial carcinoma',\n",
       " 'basal cell carcinoma',\n",
       " 'melanocytic nevi',\n",
       " 'actinic keratoses and intraepithelial carcinoma',\n",
       " 'melanoma',\n",
       " 'melanoma',\n",
       " 'melanocytic nevi',\n",
       " 'actinic keratoses and intraepithelial carcinoma']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths_for_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File zero_shot_dermamnist_openai_gpt4o_preds.txt does not exist. Creating ...\n",
      "Model predictions: ['melanocytic nevi', 'melanocytic nevi', 'melanocytic nevi', 'melanocytic nevi', 'melanocytic nevi', 'melanocytic nevi', 'melanocytic nevi', 'melanocytic nevi', 'melanocytic nevi', 'melanocytic nevi']\n",
      "Ground truths: ['dermatofibroma', 'vascular lesions', 'actinic keratoses and intraepithelial carcinoma', 'basal cell carcinoma', 'melanocytic nevi', 'actinic keratoses and intraepithelial carcinoma', 'melanoma', 'melanoma', 'melanocytic nevi', 'actinic keratoses and intraepithelial carcinoma']\n",
      "Accuracy: 0.2000\n",
      "Mean Bootstrap Accuracy: 0.1991\n",
      "Standard Deviation of Bootstrap Accuracies: 0.123892\n"
     ]
    }
   ],
   "source": [
    "# Compute result for OpenAI GPT-4o\n",
    "zero_shot_dermamnist_openai_gpt4o_preds_file = 'zero_shot_dermamnist_openai_gpt4o_preds.txt'\n",
    "\n",
    "if os.path.exists(zero_shot_dermamnist_openai_gpt4o_preds_file):\n",
    "    # print(f\"File {zero_shot_dermamnist_openai_gpt4o_preds_file} exists. Loading Results...\")\n",
    "    openai_gpt4o_preds = load_list_from_file(zero_shot_dermamnist_openai_gpt4o_preds_file)\n",
    "    matching_count = count_matching_samples_positionwise(openai_gpt4o_preds, ground_truths_for_samples)\n",
    "    accuracy_openai_gpt4o = matching_count / len(ground_truths_for_samples)\n",
    "else:\n",
    "    print(f\"File {zero_shot_dermamnist_openai_gpt4o_preds_file} does not exist. Creating ...\")\n",
    "    accuracy_openai_gpt4o, openai_gpt4o_preds = get_class_samples(\n",
    "        client_openai,\n",
    "        samples_to_use,\n",
    "        dataset_classes,\n",
    "        dataset,\n",
    "        ground_truths_for_samples,\n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"gpt-4o\"  # or \"GPT4o-mini\" for the smaller model\n",
    "    )\n",
    "    save_list_to_file(openai_gpt4o_preds, zero_shot_dermamnist_openai_gpt4o_preds_file)\n",
    "\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(openai_gpt4o_preds, ground_truths_for_samples)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File zero_shot_dermamnist_openai_gpt4o_mini_preds.txt does not exist. Creating ...\n",
      "Failed to extract valid JSON from the response.\n",
      "Model predictions: []\n",
      "Ground truths: ['dermatofibroma', 'vascular lesions', 'actinic keratoses and intraepithelial carcinoma', 'basal cell carcinoma', 'melanocytic nevi', 'actinic keratoses and intraepithelial carcinoma', 'melanoma', 'melanoma', 'melanocytic nevi', 'actinic keratoses and intraepithelial carcinoma', 'benign keratosis-like lesions', 'dermatofibroma', 'melanocytic nevi', 'melanoma', 'actinic keratoses and intraepithelial carcinoma', 'dermatofibroma', 'melanocytic nevi', 'melanocytic nevi', 'vascular lesions', 'vascular lesions', 'vascular lesions', 'dermatofibroma', 'vascular lesions', 'actinic keratoses and intraepithelial carcinoma', 'basal cell carcinoma', 'melanoma', 'basal cell carcinoma', 'dermatofibroma', 'actinic keratoses and intraepithelial carcinoma', 'melanoma', 'dermatofibroma', 'melanoma', 'benign keratosis-like lesions', 'benign keratosis-like lesions', 'melanocytic nevi', 'basal cell carcinoma', 'basal cell carcinoma', 'melanocytic nevi', 'melanoma', 'dermatofibroma', 'benign keratosis-like lesions', 'melanocytic nevi', 'benign keratosis-like lesions', 'actinic keratoses and intraepithelial carcinoma', 'melanoma', 'melanoma', 'benign keratosis-like lesions', 'benign keratosis-like lesions', 'vascular lesions', 'benign keratosis-like lesions', 'vascular lesions', 'basal cell carcinoma', 'dermatofibroma', 'actinic keratoses and intraepithelial carcinoma', 'vascular lesions', 'benign keratosis-like lesions', 'melanoma', 'basal cell carcinoma', 'benign keratosis-like lesions', 'actinic keratoses and intraepithelial carcinoma', 'dermatofibroma', 'vascular lesions', 'actinic keratoses and intraepithelial carcinoma', 'dermatofibroma', 'melanocytic nevi', 'melanocytic nevi', 'vascular lesions', 'basal cell carcinoma', 'basal cell carcinoma', 'vascular lesions', 'melanocytic nevi', 'benign keratosis-like lesions', 'dermatofibroma', 'actinic keratoses and intraepithelial carcinoma', 'melanoma', 'benign keratosis-like lesions', 'dermatofibroma', 'melanoma', 'actinic keratoses and intraepithelial carcinoma', 'melanoma', 'dermatofibroma', 'basal cell carcinoma', 'basal cell carcinoma', 'vascular lesions', 'benign keratosis-like lesions', 'basal cell carcinoma', 'vascular lesions', 'melanoma', 'melanocytic nevi', 'dermatofibroma', 'benign keratosis-like lesions', 'basal cell carcinoma', 'melanoma', 'actinic keratoses and intraepithelial carcinoma', 'melanocytic nevi', 'actinic keratoses and intraepithelial carcinoma', 'basal cell carcinoma', 'melanocytic nevi', 'vascular lesions', 'dermatofibroma']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzero_shot_dermamnist_openai_gpt4o_mini_preds_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist. Creating ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     accuracy_openai_gpt4o_mini, openai_gpt4o_mini_preds \u001b[38;5;241m=\u001b[39m \u001b[43mget_class_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_openai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43msamples_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mground_truths_for_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43munified_zero_shot_predict_class_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# The smaller GPT-4 model\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     save_list_to_file(openai_gpt4o_mini_preds, zero_shot_dermamnist_openai_gpt4o_mini_preds_file)\n\u001b[1;32m     22\u001b[0m accuracy, mean_acc, var_acc, z_score, p_value \u001b[38;5;241m=\u001b[39m compute_statistical_significance(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
      "File \u001b[0;32m~/Documents/med_gpt/HelperFunctions.py:240\u001b[0m, in \u001b[0;36mget_class_samples\u001b[0;34m(client, list_of_images, classes_to_classify, dataset_name, ground_truths, func_to_call, model, image_media_type)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Compare the predictions with the ground truth\u001b[39;00m\n\u001b[1;32m    239\u001b[0m matching_count \u001b[38;5;241m=\u001b[39m count_matching_samples_positionwise(preds, ground_truths)\n\u001b[0;32m--> 240\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmatching_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mground_truths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, preds\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# Compute result for OpenAI GPT-4o-mini\n",
    "zero_shot_dermamnist_openai_gpt4o_mini_preds_file = 'zero_shot_dermamnist_openai_gpt4o_mini_preds.txt'\n",
    "\n",
    "if os.path.exists(zero_shot_dermamnist_openai_gpt4o_mini_preds_file):\n",
    "    # print(f\"File {zero_shot_dermamnist_openai_gpt4o_mini_preds_file} exists. Loading Results...\")\n",
    "    openai_gpt4o_mini_preds = load_list_from_file(zero_shot_dermamnist_openai_gpt4o_mini_preds_file)\n",
    "    matching_count = count_matching_samples_positionwise(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
    "    accuracy_openai_gpt4o_mini = matching_count / len(ground_truths_for_samples)\n",
    "else:\n",
    "    print(f\"File {zero_shot_dermamnist_openai_gpt4o_mini_preds_file} does not exist. Creating ...\")\n",
    "    accuracy_openai_gpt4o_mini, openai_gpt4o_mini_preds = get_class_samples(\n",
    "        client_openai,\n",
    "        samples_to_use,\n",
    "        dataset_classes,\n",
    "        dataset,\n",
    "        ground_truths_for_samples,\n",
    "        unified_zero_shot_predict_class_only,\n",
    "        model=\"gpt-4o-mini\"  # The smaller GPT-4 model\n",
    "    )\n",
    "    save_list_to_file(openai_gpt4o_mini_preds, zero_shot_dermamnist_openai_gpt4o_mini_preds_file)\n",
    "\n",
    "accuracy, mean_acc, var_acc, z_score, p_value = compute_statistical_significance(openai_gpt4o_mini_preds, ground_truths_for_samples)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Mean Bootstrap Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation of Bootstrap Accuracies: {math.sqrt(var_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
